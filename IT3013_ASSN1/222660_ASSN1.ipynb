{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe26726-1657-4702-b9ed-280da429625f",
   "metadata": {},
   "source": [
    "# IT3103 Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ffba2-595d-49bf-8a00-0c44ce45b170",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24dc950-3977-44c7-b773-433c87197e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdef865-c1fa-4137-b59c-4ecd58e5c9f8",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "Imports the datasets to be used when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ff138b-6fe4-417c-bb68-d7406b7c4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file from the link\n",
    "dataset_URL = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/it3103/datasets/fruits.zip'\n",
    "\n",
    "# Extract the file into a folder\n",
    "path_to_zip = tf.keras.utils.get_file('fruits.zip', origin=dataset_URL, extract=True, cache_dir='.')\n",
    "\n",
    "# Set the path to look for the files\n",
    "dataset_dir = os.path.join(os.path.dirname(path_to_zip), \"fruits_extracted/fruits\")\n",
    "dataset_dir_valid = os.path.join(os.path.dirname(path_to_zip), \"fruits_extracted/fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1a970-b733-4ef6-8a91-2c83a8e93d89",
   "metadata": {},
   "source": [
    "### Extracting datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b6a014-a5b4-4f9b-b9e6-1c991385bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Directory\n",
    "trainingDirectory = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# Validation Directory\n",
    "validationDirectory = os.path.join(dataset_dir_valid, \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15383c45-20e1-4c6e-a92e-e5032a938467",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63676679-312a-48db-bd71-0a53c5f0ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2359808   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,733,510\n",
      "Trainable params: 2,733,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(128,128, 3)))\n",
    "    model.add(keras.layers.Rescaling(1./255))\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add\n",
    "    model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7caad6-0909-491c-b3e1-44ea25a4150e",
   "metadata": {},
   "source": [
    "### Adding Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3470764-c213-48ef-8511-928eb8deba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Categorical Crossentropy is used when truth labels are integer coded and have multiple classes\n",
    "# Categorical Crossentropy is used when it is one hot coded\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279ea6c-e804-443e-96d1-ff8674fc85b4",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8aefd32-4ad7-4a2a-a642-17c6eb522cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1182 files belonging to 6 classes.\n",
      "Found 329 files belonging to 6 classes.\n",
      "Images Shape:  (32, 128, 128, 3)\n",
      "Labels Shape:  (32,)\n",
      "tf.Tensor([2 3 0 3 4 3 4 4 1 2 4 0 4 1 2 1 3 5 1 3 2 5 1 3 4 3 3 0 3 0 0 0], shape=(32,), dtype=int32)\n",
      "['freshapples', 'freshbanana', 'freshoranges', 'rottenapples', 'rottenbanana', 'rottenoranges']\n",
      "['freshapples', 'freshbanana', 'freshoranges', 'rottenapples', 'rottenbanana', 'rottenoranges']\n"
     ]
    }
   ],
   "source": [
    "imgHeight, imgWidth = 128, 128\n",
    "batchSize = 32\n",
    "\n",
    "# Resizing all images into the smae size\n",
    "imageSize = (imgHeight, imgWidth)\n",
    "\n",
    "trainingDataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    trainingDirectory,\n",
    "    seed=1,\n",
    "    image_size=imageSize,\n",
    "    batch_size=batchSize,\n",
    "    label_mode=\"int\"\n",
    ")\n",
    "\n",
    "validationDataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    validationDirectory,\n",
    "    seed=1,\n",
    "    image_size=imageSize,\n",
    "    batch_size=batchSize,\n",
    "    label_mode=\"int\"\n",
    ")\n",
    "\n",
    "for images, labels in trainingDataset.take(1):\n",
    "    print(\"Images Shape: \", images.shape)\n",
    "    print(\"Labels Shape: \", labels.shape)\n",
    "    print(tf.squeeze(labels))\n",
    "\n",
    "# print out the indices to find out the class\n",
    "print(trainingDataset.class_names)\n",
    "print(validationDataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780233c1-af70-496c-bc21-5e658ea821c1",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae8b754-516f-4fad-ba3c-24bc57cceef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 4s 33ms/step - loss: 1.7579 - accuracy: 0.2530 - val_loss: 1.6675 - val_accuracy: 0.4043\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 1.5155 - accuracy: 0.4205 - val_loss: 1.1933 - val_accuracy: 0.5714\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 1.1403 - accuracy: 0.5525 - val_loss: 0.9912 - val_accuracy: 0.6261\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.9705 - accuracy: 0.6261 - val_loss: 0.8340 - val_accuracy: 0.6900\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.8618 - accuracy: 0.6633 - val_loss: 0.8422 - val_accuracy: 0.6748\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.7888 - accuracy: 0.6920 - val_loss: 0.7120 - val_accuracy: 0.7295\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.6930 - accuracy: 0.7403 - val_loss: 0.6856 - val_accuracy: 0.7416\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.6561 - accuracy: 0.7606 - val_loss: 0.6302 - val_accuracy: 0.7660\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.6050 - accuracy: 0.7766 - val_loss: 0.7002 - val_accuracy: 0.7264\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5815 - accuracy: 0.7860 - val_loss: 0.5408 - val_accuracy: 0.8055\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.4652 - accuracy: 0.8384 - val_loss: 0.4420 - val_accuracy: 0.8693\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.4430 - accuracy: 0.8409 - val_loss: 0.4918 - val_accuracy: 0.8359\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.4179 - accuracy: 0.8579 - val_loss: 0.4294 - val_accuracy: 0.8571\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.3804 - accuracy: 0.8672 - val_loss: 0.4020 - val_accuracy: 0.8723\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3684 - accuracy: 0.8756 - val_loss: 0.3917 - val_accuracy: 0.8632\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3519 - accuracy: 0.8773 - val_loss: 0.4197 - val_accuracy: 0.8571\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.2998 - accuracy: 0.9036 - val_loss: 0.4450 - val_accuracy: 0.8602\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.3192 - accuracy: 0.8942 - val_loss: 0.3932 - val_accuracy: 0.8784\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.2936 - accuracy: 0.8866 - val_loss: 0.3373 - val_accuracy: 0.8936\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2595 - accuracy: 0.9002 - val_loss: 0.3620 - val_accuracy: 0.8875\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2485 - accuracy: 0.9205 - val_loss: 0.3684 - val_accuracy: 0.8723\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2173 - accuracy: 0.9306 - val_loss: 0.4136 - val_accuracy: 0.8815\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2173 - accuracy: 0.9205 - val_loss: 0.3491 - val_accuracy: 0.8906\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.2252 - accuracy: 0.9171 - val_loss: 0.4589 - val_accuracy: 0.8541\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2343 - accuracy: 0.9171 - val_loss: 0.3607 - val_accuracy: 0.8906\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.1905 - accuracy: 0.9391 - val_loss: 0.3686 - val_accuracy: 0.8784\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 1s 31ms/step - loss: 0.1748 - accuracy: 0.9399 - val_loss: 0.4465 - val_accuracy: 0.8754\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.2093 - accuracy: 0.9272 - val_loss: 0.4093 - val_accuracy: 0.8754\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 1s 34ms/step - loss: 0.1568 - accuracy: 0.9467 - val_loss: 0.3213 - val_accuracy: 0.9027\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 1s 32ms/step - loss: 0.1702 - accuracy: 0.9459 - val_loss: 0.3288 - val_accuracy: 0.8906\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 1s 34ms/step - loss: 0.1481 - accuracy: 0.9475 - val_loss: 0.4360 - val_accuracy: 0.8511\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 1s 35ms/step - loss: 0.1289 - accuracy: 0.9569 - val_loss: 0.4568 - val_accuracy: 0.8784\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.1450 - accuracy: 0.9518 - val_loss: 0.3573 - val_accuracy: 0.8936\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 2s 37ms/step - loss: 0.1064 - accuracy: 0.9645 - val_loss: 0.3736 - val_accuracy: 0.8723\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.1167 - accuracy: 0.9619 - val_loss: 0.3331 - val_accuracy: 0.9027\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.0910 - accuracy: 0.9712 - val_loss: 0.3504 - val_accuracy: 0.8936\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.0835 - accuracy: 0.9755 - val_loss: 0.3660 - val_accuracy: 0.8936\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.0901 - accuracy: 0.9721 - val_loss: 0.4305 - val_accuracy: 0.8815\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.1098 - accuracy: 0.9602 - val_loss: 0.3748 - val_accuracy: 0.8875\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.1017 - accuracy: 0.9628 - val_loss: 0.3376 - val_accuracy: 0.8967\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.0859 - accuracy: 0.9721 - val_loss: 0.3327 - val_accuracy: 0.8997\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 2s 41ms/step - loss: 0.0618 - accuracy: 0.9780 - val_loss: 0.3667 - val_accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 2s 38ms/step - loss: 0.0932 - accuracy: 0.9729 - val_loss: 0.4038 - val_accuracy: 0.8845\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 2s 40ms/step - loss: 0.0797 - accuracy: 0.9704 - val_loss: 0.3514 - val_accuracy: 0.9119\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 2s 40ms/step - loss: 0.0854 - accuracy: 0.9679 - val_loss: 0.3879 - val_accuracy: 0.8875\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.0724 - accuracy: 0.9746 - val_loss: 0.3648 - val_accuracy: 0.9058\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 2s 37ms/step - loss: 0.0528 - accuracy: 0.9898 - val_loss: 0.4147 - val_accuracy: 0.8967\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 2s 37ms/step - loss: 0.1351 - accuracy: 0.9518 - val_loss: 0.4527 - val_accuracy: 0.8693\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 1s 36ms/step - loss: 0.0759 - accuracy: 0.9780 - val_loss: 0.3783 - val_accuracy: 0.9119\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 2s 39ms/step - loss: 0.0450 - accuracy: 0.9873 - val_loss: 0.3988 - val_accuracy: 0.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d8eb56140>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tb_callback():\n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "    def get_run_logdir():\n",
    "        import time\n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir, run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    return tb_callback\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"bestcheckpoint.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    trainingDataset,\n",
    "    epochs=50,\n",
    "    validation_data=validationDataset,\n",
    "    callbacks=[create_tb_callback(), model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fb0134-f160-4d31-a695-3683eed55508",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model, filepath=\"cur_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d47e1-5d1a-48a7-b454-24d1bf135940",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d31ab80-b28f-452b-b0fc-1fabaa9225bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freshapples\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "filename = \"TestImages/apple.jpg\"\n",
    "\n",
    "test_image = keras.preprocessing.image.load_img(\n",
    "    filename, target_size=(128, 128)\n",
    ")\n",
    "\n",
    "# Converts the image to numpy array\n",
    "img_array = keras.preprocessing.image.img_to_array(test_image)\n",
    "\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# Loading the model  to do the inference\n",
    "model = tf.keras.models.load_model(\"cur_model.keras\")\n",
    "predicted_label = model(img_array)\n",
    "\n",
    "class FruitType(Enum):\n",
    "    freshapples = 0\n",
    "    freshbanana = 1\n",
    "    freshoranges = 2\n",
    "    rottenapples = 3\n",
    "    rottenbanana = 4\n",
    "    rottenoranges = 5\n",
    "\n",
    "print(FruitType(np.argmax(predicted_label)).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49150d2-207a-423b-bb33-e38e97c66a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freshapples',\n",
       " 'freshbanana',\n",
       " 'freshoranges',\n",
       " 'rottenapples',\n",
       " 'rottenbanana',\n",
       " 'rottenoranges']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationDataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45997a88-68cb-404a-918a-3ac543296e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
