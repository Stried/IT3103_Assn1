{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe26726-1657-4702-b9ed-280da429625f",
   "metadata": {},
   "source": [
    "# IT3103 Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ffba2-595d-49bf-8a00-0c44ce45b170",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24dc950-3977-44c7-b773-433c87197e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdef865-c1fa-4137-b59c-4ecd58e5c9f8",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "Imports the datasets to be used when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ff138b-6fe4-417c-bb68-d7406b7c4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file from the link\n",
    "dataset_URL = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/it3103/datasets/fruits.zip'\n",
    "\n",
    "# Extract the file into a folder\n",
    "path_to_zip = tf.keras.utils.get_file('fruits.zip', origin=dataset_URL, extract=True, cache_dir='.')\n",
    "\n",
    "# Set the path to look for the files\n",
    "dataset_dir = os.path.join(os.path.dirname(path_to_zip), \"fruits_extracted/fruits\")\n",
    "dataset_dir_valid = os.path.join(os.path.dirname(path_to_zip), \"fruits_extracted/fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1a970-b733-4ef6-8a91-2c83a8e93d89",
   "metadata": {},
   "source": [
    "### Extracting datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b6a014-a5b4-4f9b-b9e6-1c991385bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Directory\n",
    "trainingDirectory = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# Validation Directory\n",
    "validationDirectory = os.path.join(dataset_dir_valid, \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15383c45-20e1-4c6e-a92e-e5032a938467",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63676679-312a-48db-bd71-0a53c5f0ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2359808   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,733,510\n",
      "Trainable params: 2,733,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(128,128, 3)))\n",
    "    model.add(keras.layers.Rescaling(1./255))\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add\n",
    "    model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7caad6-0909-491c-b3e1-44ea25a4150e",
   "metadata": {},
   "source": [
    "### Adding Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3470764-c213-48ef-8511-928eb8deba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Categorical Crossentropy is used when truth labels are integer coded and have multiple classes\n",
    "# Categorical Crossentropy is used when it is one hot coded\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279ea6c-e804-443e-96d1-ff8674fc85b4",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8aefd32-4ad7-4a2a-a642-17c6eb522cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1182 files belonging to 6 classes.\n",
      "Found 329 files belonging to 6 classes.\n",
      "Images Shape:  (32, 128, 128, 3)\n",
      "Labels Shape:  (32,)\n",
      "tf.Tensor([2 3 0 3 4 3 4 4 1 2 4 0 4 1 2 1 3 5 1 3 2 5 1 3 4 3 3 0 3 0 0 0], shape=(32,), dtype=int32)\n",
      "['freshapples', 'freshbanana', 'freshoranges', 'rottenapples', 'rottenbanana', 'rottenoranges']\n",
      "['freshapples', 'freshbanana', 'freshoranges', 'rottenapples', 'rottenbanana', 'rottenoranges']\n"
     ]
    }
   ],
   "source": [
    "imgHeight, imgWidth = 128, 128\n",
    "batchSize = 32\n",
    "\n",
    "# Resizing all images into the smae size\n",
    "imageSize = (imgHeight, imgWidth)\n",
    "\n",
    "trainingDataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    trainingDirectory,\n",
    "    seed=1,\n",
    "    image_size=imageSize,\n",
    "    batch_size=batchSize,\n",
    "    label_mode=\"int\"\n",
    ")\n",
    "\n",
    "validationDataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    validationDirectory,\n",
    "    seed=1,\n",
    "    image_size=imageSize,\n",
    "    batch_size=batchSize,\n",
    "    label_mode=\"int\"\n",
    ")\n",
    "\n",
    "for images, labels in trainingDataset.take(1):\n",
    "    print(\"Images Shape: \", images.shape)\n",
    "    print(\"Labels Shape: \", labels.shape)\n",
    "    print(tf.squeeze(labels))\n",
    "\n",
    "# print out the indices to find out the class\n",
    "print(trainingDataset.class_names)\n",
    "print(validationDataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780233c1-af70-496c-bc21-5e658ea821c1",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae8b754-516f-4fad-ba3c-24bc57cceef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 97s 34ms/step - loss: 1.7417 - accuracy: 0.2631 - val_loss: 1.6011 - val_accuracy: 0.3891\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 1.4197 - accuracy: 0.4382 - val_loss: 1.1635 - val_accuracy: 0.5805\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 1.1380 - accuracy: 0.5635 - val_loss: 0.9909 - val_accuracy: 0.6322\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.9484 - accuracy: 0.6337 - val_loss: 0.8637 - val_accuracy: 0.6900\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.8524 - accuracy: 0.6709 - val_loss: 0.7839 - val_accuracy: 0.7173\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.7653 - accuracy: 0.7191 - val_loss: 0.7374 - val_accuracy: 0.7204\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.6792 - accuracy: 0.7547 - val_loss: 0.6588 - val_accuracy: 0.7690\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5986 - accuracy: 0.7885 - val_loss: 0.6566 - val_accuracy: 0.7690\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5332 - accuracy: 0.8266 - val_loss: 0.4920 - val_accuracy: 0.8450\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.4686 - accuracy: 0.8384 - val_loss: 0.5125 - val_accuracy: 0.8298\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.4400 - accuracy: 0.8469 - val_loss: 0.4367 - val_accuracy: 0.8632\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3919 - accuracy: 0.8680 - val_loss: 0.4150 - val_accuracy: 0.8571\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3545 - accuracy: 0.8849 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.3301 - accuracy: 0.8883 - val_loss: 0.4037 - val_accuracy: 0.8541\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.3501 - accuracy: 0.8689 - val_loss: 0.4076 - val_accuracy: 0.8663\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.3233 - accuracy: 0.8816 - val_loss: 0.3506 - val_accuracy: 0.8936\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2791 - accuracy: 0.9036 - val_loss: 0.4192 - val_accuracy: 0.8571\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3183 - accuracy: 0.8892 - val_loss: 0.3708 - val_accuracy: 0.8784\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2875 - accuracy: 0.9027 - val_loss: 0.3556 - val_accuracy: 0.8906\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.2338 - accuracy: 0.9239 - val_loss: 0.3484 - val_accuracy: 0.8906\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.2332 - accuracy: 0.9239 - val_loss: 0.3386 - val_accuracy: 0.9058\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.2151 - accuracy: 0.9162 - val_loss: 0.3732 - val_accuracy: 0.8936\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.1931 - accuracy: 0.9315 - val_loss: 0.3473 - val_accuracy: 0.8906\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.2058 - accuracy: 0.9247 - val_loss: 0.3366 - val_accuracy: 0.9027\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.1816 - accuracy: 0.9365 - val_loss: 0.3020 - val_accuracy: 0.8967\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.1584 - accuracy: 0.9459 - val_loss: 0.3143 - val_accuracy: 0.9058\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.1442 - accuracy: 0.9509 - val_loss: 0.3792 - val_accuracy: 0.8906\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.1876 - accuracy: 0.9281 - val_loss: 0.3157 - val_accuracy: 0.9027\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.1443 - accuracy: 0.9535 - val_loss: 0.3372 - val_accuracy: 0.8845\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.1669 - accuracy: 0.9332 - val_loss: 0.3342 - val_accuracy: 0.9027\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.1329 - accuracy: 0.9569 - val_loss: 0.3234 - val_accuracy: 0.8875\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.1408 - accuracy: 0.9484 - val_loss: 0.3961 - val_accuracy: 0.8906\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.1201 - accuracy: 0.9535 - val_loss: 0.3302 - val_accuracy: 0.9058\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.1161 - accuracy: 0.9585 - val_loss: 0.3116 - val_accuracy: 0.9088\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.1184 - accuracy: 0.9628 - val_loss: 0.2887 - val_accuracy: 0.9119\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0910 - accuracy: 0.9738 - val_loss: 0.3184 - val_accuracy: 0.9058\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.0786 - accuracy: 0.9721 - val_loss: 0.3220 - val_accuracy: 0.9058\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.0671 - accuracy: 0.9805 - val_loss: 0.3298 - val_accuracy: 0.9058\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.0812 - accuracy: 0.9721 - val_loss: 0.3190 - val_accuracy: 0.9027\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 0.3099 - val_accuracy: 0.9119\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.0863 - accuracy: 0.9729 - val_loss: 0.3359 - val_accuracy: 0.9058\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0697 - accuracy: 0.9788 - val_loss: 0.3225 - val_accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.0674 - accuracy: 0.9772 - val_loss: 0.3623 - val_accuracy: 0.8997\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.0587 - accuracy: 0.9839 - val_loss: 0.3852 - val_accuracy: 0.9088\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 0.3351 - val_accuracy: 0.9027\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0545 - accuracy: 0.9865 - val_loss: 0.3158 - val_accuracy: 0.9088\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.3386 - val_accuracy: 0.9149\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0582 - accuracy: 0.9814 - val_loss: 0.3585 - val_accuracy: 0.9027\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.0592 - accuracy: 0.9839 - val_loss: 0.3581 - val_accuracy: 0.8967\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.0520 - accuracy: 0.9822 - val_loss: 0.4067 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27051da6f50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tb_callback():\n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "    def get_run_logdir():\n",
    "        import time\n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir, run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    return tb_callback\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"bestcheckpoint.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    trainingDataset,\n",
    "    epochs=50,\n",
    "    validation_data=validationDataset,\n",
    "    callbacks=[create_tb_callback(), model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fb0134-f160-4d31-a695-3683eed55508",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model, filepath=\"cur_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d47e1-5d1a-48a7-b454-24d1bf135940",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d31ab80-b28f-452b-b0fc-1fabaa9225bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rottenoranges\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "filename = \"TestImages/apple.jpg\"\n",
    "\n",
    "test_image = keras.preprocessing.image.load_img(\n",
    "    filename, target_size=(128, 128)\n",
    ")\n",
    "\n",
    "# Converts the image to numpy array\n",
    "img_array = keras.preprocessing.image.img_to_array(test_image)\n",
    "\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# Loading the model  to do the inference\n",
    "model = tf.keras.models.load_model(\"cur_model.keras\")\n",
    "predicted_label = model(img_array)\n",
    "\n",
    "class FruitType(Enum):\n",
    "    freshapples = 0\n",
    "    freshbanana = 1\n",
    "    freshoranges = 2\n",
    "    rottenapples = 3\n",
    "    rottenbanana = 4\n",
    "    rottenoranges = 5\n",
    "\n",
    "print(FruitType(np.argmax(predicted_label)).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49150d2-207a-423b-bb33-e38e97c66a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freshapples',\n",
       " 'freshbanana',\n",
       " 'freshoranges',\n",
       " 'rottenapples',\n",
       " 'rottenbanana',\n",
       " 'rottenoranges']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationDataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45997a88-68cb-404a-918a-3ac543296e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
